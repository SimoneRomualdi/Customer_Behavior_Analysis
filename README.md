# ğŸ›ï¸ Customer Shopping Behavior â€” Analisi e Dashboard

## ğŸ“Œ Descrizione del Progetto

Questo progetto analizza il comportamento d'acquisto di un campione di clienti, partendo dalla pulizia e trasformazione dei dati raw fino alla creazione di una dashboard interattiva. L'obiettivo Ã¨ estrarre insight utili su segmenti di clientela, preferenze di prodotto, efficacia degli sconti e pattern di acquisto.

---

## ğŸ—‚ï¸ Struttura della Repository

```
â”œâ”€â”€ script_python/
â”‚   â””â”€â”€ Customer_Shopping_Analisi_Comportamento.ipynb   # Notebook di data cleaning e feature engineering
â”œâ”€â”€ scripts_sql/
â”‚   â”œâ”€â”€ 00_DDL_Database_SQL.sql                          # Schema del database PostgreSQL
â”‚   â””â”€â”€ SQL_Queries.sql                                  # Query di analisi
â””â”€â”€ README.md
```

---
Dashboard

![Dashboard](Screenshot_Dashboard.png)

## ğŸ”„ Pipeline del Progetto

### 1. Data Cleaning & Feature Engineering (Python / Pandas)

Il notebook si occupa di preparare il dataset `customer_shopping_behavior.csv` per l'analisi:

- **Esplorazione iniziale**: ispezione della struttura, tipi di dato e valori nulli
- **Gestione dei missing values**: i valori mancanti di `Review Rating` vengono imputati con la mediana calcolata per categoria merceologica
- **Normalizzazione dei nomi delle colonne**: tutti i nomi sono convertiti in lowercase con underscore per uniformitÃ 
- **Creazione di nuove feature**:
  - `age_groups`: segmentazione dei clienti in 4 fasce d'etÃ  tramite quantili (Giovane Adulto, Adulto, Mezza EtÃ , Senior)
  - `purchase_frequency_days`: conversione della frequenza d'acquisto testuale in valore numerico (es. "Weekly" â†’ 7)
- **Rimozione di colonne ridondanti**: `promo_code_used` risulta identica a `discount_applied` e viene rimossa
- **Export**: il dataset pulito viene salvato come `customer_behavior.csv` per il caricamento su PostgreSQL

### 2. Database Setup (SQL / PostgreSQL)

Il file DDL definisce la tabella `customer_behavior` su PostgreSQL con i tipi di dato appropriati, pronta per accogliere il dataset processato dal notebook.

### 3. Analisi con SQL

Le query coprono diversi ambiti di analisi:

| Area | Esempi di analisi |
|---|---|
| **Revenue** | Totale vendite per genere, contributo per fascia d'etÃ  |
| **Prodotti** | Top 5 per media recensioni, top 3 per categoria, % sconto applicato |
| **Clienti** | Abbonati vs non abbonati, segmentazione per storico acquisti |
| **Spedizioni** | Confronto spesa media Standard vs Express |
| **Sconti** | Clienti con sconto che superano la spesa media |

Tecniche SQL utilizzate: subquery, CTE (`WITH`), window functions (`ROW_NUMBER`, `SUM OVER`), `CASE WHEN`, `ROUND` con cast esplicito.

---

## ğŸ› ï¸ Tecnologie Utilizzate

- **Python** â€” Pandas, Jupyter Notebook
- **SQL** â€” PostgreSQL
- **BI Tool** â€” PowerBI

---

## ğŸ“Š Dataset

Il dataset originale contiene **3.900 record** e **18 colonne**, con informazioni su clienti di un e-commerce: etÃ , genere, prodotti acquistati, importo, metodo di pagamento, tipo di spedizione, stato abbonamento e frequenza d'acquisto.
